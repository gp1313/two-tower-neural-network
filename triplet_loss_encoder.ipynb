{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04dbe13-bd7b-459b-8095-5550c974d938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  0  loss: 0.389 time : 11.59s\n",
      "batch_idx:  1  loss: 0.442 time : 10.72s\n",
      "batch_idx:  2  loss: 0.304 time : 11.49s\n",
      "batch_idx:  3  loss: 0.279 time : 10.97s\n",
      "batch_idx:  4  loss: 0.274 time : 11.14s\n",
      "batch_idx:  5  loss: 0.241 time : 11.86s\n",
      "batch_idx:  6  loss: 0.226 time : 10.73s\n",
      "batch_idx:  7  loss: 0.212 time : 11.16s\n",
      "batch_idx:  8  loss: 0.210 time : 10.72s\n",
      "batch_idx:  9  loss: 0.224 time : 10.98s\n",
      "batch_idx: 10  loss: 0.191 time : 10.72s\n",
      "batch_idx: 11  loss: 0.196 time : 11.26s\n",
      "batch_idx: 12  loss: 0.182 time : 11.16s\n",
      "batch_idx: 13  loss: 0.179 time : 10.91s\n",
      "batch_idx: 14  loss: 0.170 time : 11.16s\n",
      "batch_idx: 15  loss: 0.158 time : 10.81s\n",
      "batch_idx: 16  loss: 0.179 time : 10.62s\n",
      "batch_idx: 17  loss: 0.136 time : 10.57s\n",
      "batch_idx: 18  loss: 0.127 time : 11.07s\n",
      "batch_idx: 19  loss: 0.139 time : 9.97s\n",
      "batch_idx: 20  loss: 0.109 time : 11.39s\n",
      "batch_idx: 21  loss: 0.142 time : 10.38s\n",
      "batch_idx: 22  loss: 0.120 time : 10.84s\n",
      "batch_idx: 23  loss: 0.122 time : 11.05s\n",
      "batch_idx: 24  loss: 0.169 time : 10.67s\n",
      "batch_idx: 25  loss: 0.131 time : 12.08s\n",
      "batch_idx: 26  loss: 0.155 time : 10.55s\n",
      "batch_idx: 27  loss: 0.156 time : 10.39s\n",
      "batch_idx: 28  loss: 0.123 time : 10.54s\n",
      "batch_idx: 29  loss: 0.145 time : 10.39s\n",
      "batch_idx: 30  loss: 0.087 time : 10.59s\n",
      "batch_idx: 31  loss: 0.134 time : 10.59s\n",
      "batch_idx: 32  loss: 0.119 time : 10.92s\n",
      "batch_idx: 33  loss: 0.133 time : 10.32s\n",
      "batch_idx: 34  loss: 0.097 time : 10.69s\n",
      "batch_idx: 35  loss: 0.089 time : 10.40s\n",
      "batch_idx: 36  loss: 0.086 time : 11.01s\n",
      "batch_idx: 37  loss: 0.117 time : 10.26s\n",
      "batch_idx: 38  loss: 0.111 time : 10.79s\n",
      "batch_idx: 39  loss: 0.128 time : 10.52s\n",
      "batch_idx: 40  loss: 0.113 time : 11.14s\n",
      "batch_idx: 41  loss: 0.112 time : 10.64s\n",
      "batch_idx: 42  loss: 0.102 time : 10.87s\n",
      "batch_idx: 43  loss: 0.087 time : 11.04s\n",
      "batch_idx: 44  loss: 0.105 time : 10.51s\n",
      "batch_idx: 45  loss: 0.085 time : 10.57s\n",
      "batch_idx: 46  loss: 0.105 time : 11.06s\n",
      "batch_idx: 47  loss: 0.057 time : 10.57s\n",
      "batch_idx: 48  loss: 0.067 time : 10.64s\n",
      "batch_idx: 49  loss: 0.074 time : 10.90s\n",
      "batch_idx: 50  loss: 0.076 time : 10.56s\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import datasets\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root=\"./mnist\", train=True,  download=True, transform=transform)\n",
    "mnist_test  = torchvision.datasets.MNIST(root=\"./mnist\", train=False, download=True, transform=transform)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 256 + 64\n",
    "lr = 3e-3\n",
    "embd_n = 128\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,    32, (3, 3))\n",
    "        self.conv2 = nn.Conv2d(32,   64, (3, 3))\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1   = nn.Linear(9216, 2048)\n",
    "        self.fc2   = nn.Linear(2048, embd_n)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # B, 1, 28, 28 ==> B, 32, 26, 26\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x) # B, 32, 26, 26 ==> B, 64, 24, 24\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool(x) # B, 64, 12, 12\n",
    "        x = self.flatten(x) # B, 9216\n",
    "        x = self.fc1(x) # B, 2048\n",
    "        x = self.fc2(x) # B, embed_n\n",
    "        # Normalize using L2 norm\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Encoder()\n",
    "model = model.to(device)\n",
    "optim = AdamW(model.parameters(), lr=lr)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_dl  = torch.utils.data.DataLoader(dataset=mnist_test, batch_size=batch_size, shuffle=True)\n",
    "margin = torch.tensor(0.5, device=device)\n",
    "\n",
    "for batch_idx, (data, labels) in enumerate(train_dl):\n",
    "    t0 = time.time()\n",
    "    data = data.to(device)\n",
    "    data_map = defaultdict(list)\n",
    "    for idx, class_idx in enumerate(labels.tolist()):\n",
    "        data_map[class_idx].append(idx)\n",
    "    embeddings = model(data)\n",
    "    optim.zero_grad()\n",
    "    triplets_idx = []\n",
    "    for class_idx in data_map:\n",
    "        n = len(data_map[class_idx])\n",
    "        neg_idx_list = [l for l in labels.tolist() if l not in data_map[class_idx]]\n",
    "        for i in range(n):\n",
    "            anc_idx = data_map[class_idx][i]\n",
    "            for j in range(i+1, n):\n",
    "                pos_idx = data_map[class_idx][j]\n",
    "                for neg_idx in neg_idx_list:\n",
    "                    triplets_idx.append(torch.tensor([anc_idx, pos_idx, neg_idx]))\n",
    "    triplets_tensor = embeddings[torch.stack(triplets_idx, dim=0)]\n",
    "    loss = torch.relu(torch.multiply(triplets_tensor[:, 0, :], triplets_tensor[:, 2, :]).sum(dim=1) - torch.multiply(triplets_tensor[:, 0, :], triplets_tensor[:, 1, :]).sum(dim=1) + margin).mean()\n",
    "    #print(f\"loss: {loss.item()}\")\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    print(f\"batch_idx: {batch_idx:2d}  loss: {loss.item():.3f} time : {(time.time() - t0):.2f}s\")\n",
    "    if batch_idx == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b57f0a75-fac9-47d2-8df1-0cd8258c4584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=9216, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "384aeac2-ae82-4c87-b8c9-4b50f0dd2afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9a54b8-f10b-4977-9b3f-06e481bcffbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=9216, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e652de-4018-4d6b-8627-584b81c1ccdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_embeddings_arr = []\n",
    "train_labels_arr = []\n",
    "for idx, (data, labels) in enumerate(train_dl):\n",
    "    embeddings = model(data)\n",
    "    train_embeddings_arr.extend(embeddings)\n",
    "    train_labels_arr.extend(labels)\n",
    "    del data\n",
    "    del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "255f3189-3e5d-4da5-902e-fe0baa477d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_emebddings_tensors = torch.stack(train_embeddings_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218713ae-e73d-4160-bba5-7e10a1bb9d65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emebddings_tensors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f3b8f-2975-414e-bf32-12446379f06a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_embeddings_arr = []\n",
    "train_labels_arr = []\n",
    "i = 0\n",
    "for idx, (data, labels) in enumerate(train_dl):\n",
    "    data = data.to(device)\n",
    "    embeddings = model(data)\n",
    "    train_embeddings_arr.extend(embeddings)\n",
    "    train_labels_arr.extend(labels)\n",
    "    if idx == 50:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
