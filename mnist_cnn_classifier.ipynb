{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04dbe13-bd7b-459b-8095-5550c974d938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss: 2.29 test acc: 0.2347\n",
      "test avg loss: 0.11 test acc: 0.9712\n",
      "test avg loss: 0.19 test acc: 0.9742\n",
      "test avg loss: 0.03 test acc: 0.9801\n",
      "test avg loss: 0.08 test acc: 0.9829\n",
      "test avg loss: 0.14 test acc: 0.9789\n",
      "test avg loss: 0.06 test acc: 0.976\n",
      "test avg loss: 0.06 test acc: 0.9749\n",
      "test avg loss: 0.07 test acc: 0.9814\n",
      "test avg loss: 0.02 test acc: 0.984\n",
      "test avg loss: 0.04 test acc: 0.9843\n",
      "test avg loss: 0.04 test acc: 0.9819\n",
      "test avg loss: 0.04 test acc: 0.9822\n",
      "test avg loss: 0.08 test acc: 0.9773\n",
      "test avg loss: 0.04 test acc: 0.9831\n",
      "test avg loss: 0.03 test acc: 0.9801\n",
      "test avg loss: 0.02 test acc: 0.983\n",
      "test avg loss: 0.02 test acc: 0.9858\n",
      "test avg loss: 0.02 test acc: 0.9836\n",
      "test avg loss: 0.04 test acc: 0.9832\n",
      "test avg loss: 0.06 test acc: 0.9798\n",
      "test avg loss: 0.02 test acc: 0.9812\n",
      "test avg loss: 0.02 test acc: 0.9807\n",
      "test avg loss: 0.08 test acc: 0.9804\n",
      "test avg loss: 0.02 test acc: 0.984\n",
      "test avg loss: 0.05 test acc: 0.9846\n",
      "test avg loss: 0.02 test acc: 0.9829\n",
      "test avg loss: 0.05 test acc: 0.9839\n",
      "test avg loss: 0.00 test acc: 0.9822\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import datasets\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root=\"./mnist\", train=True,  download=True, transform=transform)\n",
    "mnist_test  = torchvision.datasets.MNIST(root=\"./mnist\", train=False, download=True, transform=transform)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,    32, (3, 3))\n",
    "        self.conv2 = nn.Conv2d(32,   64, (3, 3))\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1   = nn.Linear(9216, 2048)\n",
    "        self.fc2   = nn.Linear(2048, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # B, 1, 28, 28 ==> B, 32, 26, 26\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x) # B, 32, 26, 26 ==> B, 64, 24, 24\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool(x) # B, 64, 12, 12\n",
    "        x = self.flatten(x) # B, 9216\n",
    "        x = self.fc1(x) # B, 2048\n",
    "        x = self.fc2(x) # B, 10\n",
    "        return x\n",
    "\n",
    "batch_size = 256\n",
    "lr = 3e-3\n",
    "\n",
    "model = Encoder()\n",
    "model = model.to(device)\n",
    "optim = AdamW(model.parameters(), lr=lr)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_dl  = torch.utils.data.DataLoader(dataset=mnist_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for idx, (data, labels) in enumerate(train_dl):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optim.zero_grad()\n",
    "        logits = model(data)\n",
    "        loss = ce_loss(logits, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if idx % 100 == 0:\n",
    "            loss_arr, preds_arr, labels_arr = [], [], []\n",
    "            for test_data, test_labels in test_dl:\n",
    "                test_data   = test_data.to(device)\n",
    "                #test_labels = test_labels.to(device)\n",
    "                logits = model(test_data)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                #preds = preds.to(\"cpu\")\n",
    "                #acc = accuracy_score(preds.cpu(), test_labels)\n",
    "                loss_arr.append(loss.item())\n",
    "                preds_arr.extend(preds.cpu())\n",
    "                labels_arr.extend(test_labels)\n",
    "            print(f\"test avg loss: {np.mean(loss_arr):.02f} test acc: {accuracy_score(preds_arr, labels_arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedab01-30a0-4f0b-be2f-79e1f02972ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e655e-0983-4f77-99bd-c252c6d4bd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
